{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf6dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import rasterio\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import hypergeom\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfad65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --path--\n",
    "# era5land_quarterly_data = \"/vast/bzaitch1/trp_climate_model_data/era5land_1970_2024_qtrmean\" # Location on Rockfish\n",
    "# output_directory  = \"/vast/bzaitch1/trp_climate_model_data/out\"\n",
    "# os.makedirs(output_directory, exist_ok=True)\n",
    "# quarter_dir = Path(rf\"E:\\backup\\trp_climate_model_data\\era5land_1970_2024_qtrmean\")\n",
    "\n",
    "quarter_dir = Path(\"/Users/kris/Local Job Backup/test set/\") # Location on local machine\n",
    "world_shp = gpd.read_file('data/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp')\n",
    "test_data_set = quarter_dir / '*.nc'\n",
    "years = range(2001, 2020)\n",
    "quarters = range(1, 5)\n",
    "pattern_per_month = \"{y}_Q{q}_qmean.nc\"   # for one file per month\n",
    "grid_data_list =[]\n",
    "\n",
    "# Hourly filename pattern:\n",
    "# One file per month:    YYYY_MM.nc\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        data_file_name = quarter_dir / pattern_per_month.format(y=year, q=quarter)\n",
    "        grid_data_list.append(data_file_name)\n",
    "\n",
    "\n",
    "cvar_aliases = {\n",
    "    'tp' : 'total precipitation', \n",
    "    't2m' : '2 metre temperature',\n",
    "    'e' : 'evaporation',\n",
    "}\n",
    "\n",
    "evar_aliases = {\n",
    "    'y' : 'Log of real GDP', \n",
    "    'Dp' : 'Inflation rate (Based on CPI)',\n",
    "    'eq' : 'Log of real equity prices',\n",
    "    'ep' : 'Log of real exchange rate',\n",
    "    'r' : 'Short-term interest rate',\n",
    "    'lr' : 'Long-term interest rate',\n",
    "}\n",
    "\n",
    "country_study_sites = ['India', 'Brazil', \n",
    "                       'Chile', 'Indonesia', \n",
    "                       'Mexico', 'Peru', \n",
    "                       'Philippines', 'South Africa', \n",
    "                       'Thailand', 'Kenya',\n",
    "                       'Egypt', 'Columbia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9c1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_ds = xr.open_dataset(grid_data_list[1])\n",
    "#instance_ds\n",
    "\n",
    "lats = instance_ds['latitude'].values\n",
    "lons = instance_ds['longitude'].values\n",
    "lons = np.where(lons > 180, lons - 360, lons) # same as SPEI and crop\n",
    "ds = instance_ds.assign_coords(longitude=lons)\n",
    "\n",
    "# Create meshgrid of lat/lon pairs\n",
    "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "coordinates = np.column_stack([lon_grid.ravel(), lat_grid.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afe07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.1,  0.2, ..., -0.3, -0.2, -0.1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- fix longitude from 0..360 to -180..180 and sort ---\n",
    "if float(da.longitude.max()) > 180:\n",
    "    lon_new = ((da.longitude + 180) % 360) - 180\n",
    "    da = da.assign_coords(longitude=lon_new).sortby(\"longitude\")\n",
    "\n",
    "# --- make latitude ascending (optional but helpful for weights) ---\n",
    "if da.latitude[0] > da.latitude[-1]:\n",
    "    da = da.sortby(\"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f4323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:03<00:00,  5.33s/it]\n"
     ]
    }
   ],
   "source": [
    "world = gpd.read_file('data/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp')\n",
    "\n",
    "mask_dict = {}\n",
    "points_in_countries_all = {}\n",
    "#points_idx_climate = {}\n",
    "\n",
    "for country_name in tqdm(country_study_sites):\n",
    "    country = world[world['SOVEREIGNT'] == country_name]\n",
    "    # Create a GeoDataFrame with the mesh grid points\n",
    "    points_gdf = gpd.GeoDataFrame(pd.DataFrame(coordinates, columns=['Longitude', 'Latitude']),\n",
    "                                geometry=gpd.points_from_xy(coordinates[:, 0], coordinates[:, 1]), crs=\"EPSG:4326\" )\n",
    "    \n",
    "    points_in_countries =  gpd.sjoin(points_gdf, country, predicate='within')\n",
    "    points_in_countries_all[country_name] = points_in_countries\n",
    "    # mask = np.zeros(lon_grid.shape, dtype=bool)\n",
    "\n",
    "    # indices = points_in_countries.index.values\n",
    "    # mask[np.unravel_index(indices, lon_grid.shape)] = True\n",
    "    # mask_dict[country_name] = mask\n",
    "    \n",
    "    # index = []\n",
    "    # for lon, lat in points_in_countries[['Longitude', 'Latitude']].values:\n",
    "    #     # Find the index of the closest point\n",
    "    #     lat_idx = abs(ds['latitude'] - lat).argmin().item()\n",
    "    #     lon_idx = abs(ds['longitude'] - lon).argmin().item()\n",
    "    #     index.append([lat_idx, lon_idx])\n",
    "    # points_idx_climate[country_name] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3346e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a pickle file\n",
    "with open(\"data/lon_lat_12c.pkl\", \"wb\") as file:\n",
    "    pickle.dump(points_in_countries_all, file)\n",
    "\n",
    "with open(\"data/lon_lat_12c.pkl\", \"rb\") as file:\n",
    "    points_in_countries_all = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ccaa353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3055793, 3055794, 3055796, ..., 4452667, 4452668, 4456266])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_in_countries_all['Brazil'].index.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
