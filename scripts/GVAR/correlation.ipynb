{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a8c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "\n",
    "os.getcwd()\n",
    "# HDF5 locking issues (Rockfish/HPC): set once per process if needed\n",
    "os.environ.setdefault(\"HDF5_USE_FILE_LOCKING\", \"FALSE\")\n",
    "os.environ[\"NETCDF_HDF5_FILE_LOCKING\"] = \"FALSE\"\n",
    "os.system('module load nco') # load up nco modules \n",
    "os.system('set -euo pipefail')\n",
    "\n",
    "#xr.set_options(file_cache_maxsize=1)  # avoid netCDF4 cache bloat\n",
    "xr.set_options(display_style=\"text\")\n",
    "\n",
    "# --path--\n",
    "era5land_hourly_data = \"/vast/bzaitch1/trp_climate_model_data/era5land_1970_2024_hourly/\"\n",
    "output_directory  = \"/vast/bzaitch1/trp_climate_model_data/out\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "# xr.open_dataset(era5land_hourly_data + \"1970_01.nc\")\n",
    "var_aliases = {\n",
    "    'tp' : 'total precipitation', \n",
    "    't2m' : '2 metre temperature',\n",
    "    'e':'evaporation',\n",
    "}\n",
    "\n",
    "df = pd.ExcelFile(\"./df_country_data_climate.xlsx\")\n",
    "list_countries = df.sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700cf17",
   "metadata": {},
   "source": [
    "Assume ```Q-DEC``` : Q1 = Jan–Mar, Q4 ends Dec (this is the most common)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUARTER_RULE = \"Q-DEC\"  # change if your macro data uses a different fiscal year-end\n",
    "econ = pd.read_excel(df, sheet_name='Argentina')\n",
    "econ[\"time\"] = pd.PeriodIndex(econ['Unnamed: 0'], freq=QUARTER_RULE).to_timestamp(how=\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d01672fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1979-06-30 23:59:59.999999999\n",
       "1     1979-09-30 23:59:59.999999999\n",
       "2     1979-12-31 23:59:59.999999999\n",
       "3     1980-03-31 23:59:59.999999999\n",
       "4     1980-06-30 23:59:59.999999999\n",
       "                   ...             \n",
       "158   2018-12-31 23:59:59.999999999\n",
       "159   2019-03-31 23:59:59.999999999\n",
       "160   2019-06-30 23:59:59.999999999\n",
       "161   2019-09-30 23:59:59.999999999\n",
       "162   2019-12-31 23:59:59.999999999\n",
       "Name: time, Length: 163, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econ[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b7130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(era5land_hourly_data + \"1970_01.nc\")\n",
    "#da = ds['t2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2c43d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt; Size: 58GB\n",
       "Dimensions:     (valid_time: 744, latitude: 1801, longitude: 3600)\n",
       "Coordinates:\n",
       "    number      int64 8B ...\n",
       "  * valid_time  (valid_time) datetime64[ns] 6kB 1970-01-01 ... 1970-01-31T23:...\n",
       "  * latitude    (latitude) float64 14kB 90.0 89.9 89.8 ... -89.8 -89.9 -90.0\n",
       "  * longitude   (longitude) float64 29kB 0.0 0.1 0.2 0.3 ... 359.7 359.8 359.9\n",
       "    expver      (valid_time) &lt;U4 12kB dask.array&lt;chunksize=(744,), meta=np.ndarray&gt;\n",
       "Data variables:\n",
       "    tp          (valid_time, latitude, longitude) float32 19GB dask.array&lt;chunksize=(68, 164, 328), meta=np.ndarray&gt;\n",
       "    t2m         (valid_time, latitude, longitude) float32 19GB dask.array&lt;chunksize=(68, 164, 328), meta=np.ndarray&gt;\n",
       "    e           (valid_time, latitude, longitude) float32 19GB dask.array&lt;chunksize=(68, 164, 328), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    GRIB_centre:             ecmf\n",
       "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             European Centre for Medium-Range Weather Forecasts\n",
       "    history:                 2025-06-03T00:39 GRIB to CDM+CF via cfgrib-0.9.1...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 58GB\n",
       "Dimensions:     (valid_time: 744, latitude: 1801, longitude: 3600)\n",
       "Coordinates:\n",
       "    number      int64 8B ...\n",
       "  * valid_time  (valid_time) datetime64[ns] 6kB 1970-01-01 ... 1970-01-31T23:...\n",
       "  * latitude    (latitude) float64 14kB 90.0 89.9 89.8 ... -89.8 -89.9 -90.0\n",
       "  * longitude   (longitude) float64 29kB 0.0 0.1 0.2 0.3 ... 359.7 359.8 359.9\n",
       "    expver      (valid_time) <U4 12kB dask.array<chunksize=(744,), meta=np.ndarray>\n",
       "Data variables:\n",
       "    tp          (valid_time, latitude, longitude) float32 19GB dask.array<chunksize=(68, 164, 328), meta=np.ndarray>\n",
       "    t2m         (valid_time, latitude, longitude) float32 19GB dask.array<chunksize=(68, 164, 328), meta=np.ndarray>\n",
       "    e           (valid_time, latitude, longitude) float32 19GB dask.array<chunksize=(68, 164, 328), meta=np.ndarray>\n",
       "Attributes:\n",
       "    GRIB_centre:             ecmf\n",
       "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             European Centre for Medium-Range Weather Forecasts\n",
       "    history:                 2025-06-03T00:39 GRIB to CDM+CF via cfgrib-0.9.1..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec597a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e9db4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "da = ds['t2m']\n",
    "# --- rename dims to standard names ---\n",
    "da = da.rename({\"valid_time\": \"time\", \"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "\n",
    "# --- rechunk for faster resampling & masking (tune to your RAM/cluster) ---\n",
    "da = da.chunk({\"time\": 24*31, \"lat\": 200, \"lon\": 300})  # ~monthly time chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c71fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- fix longitude from 0..360 to -180..180 and sort ---\n",
    "if float(da.lon.max()) > 180:\n",
    "    lon_new = ((da.lon + 180) % 360) - 180\n",
    "    da = da.assign_coords(lon=lon_new).sortby(\"lon\")\n",
    "\n",
    "# --- make latitude ascending (optional but helpful for weights) ---\n",
    "if da.lat[0] > da.lat[-1]:\n",
    "    da = da.sortby(\"lat\")\n",
    "\n",
    "# --- convert K -> °C ---\n",
    "if str(da.attrs.get(\"units\", \"\")).lower() in (\"k\", \"kelvin\"):\n",
    "    da = da - 273.15\n",
    "    da.attrs[\"units\"] = \"degC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrend_dim(da, dim, deg=1):    #subtracts linear fit)\n",
    "    p = da.polyfit(dim=dim, deg=deg)\n",
    "    fit = xr.polyval(da[dim], p.polyfit_coefficients)\n",
    "    return da - fit\n",
    "\n",
    "def det_data(ds):\n",
    "    climatology = ds.groupby(\"time.month\").mean(\"time\") #calculates seasonality\n",
    "    anomalies = ds.groupby(\"time.month\") - climatology  #removes seasonality\n",
    "    #ga = anomalies.mean(dim = ['lat','lon'])\n",
    "    detrend = detrend_dim(anomalies,'time') #calls to detrend_dim function, subtracts linear fit\n",
    "    return detrend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
