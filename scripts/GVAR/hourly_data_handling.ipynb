{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a54dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 32 CPU cores\n",
      "Dask Client initialized with 31 workers\n",
      "Dashboard available at: http://127.0.0.1:8787/status\n",
      "<Client: 'tcp://127.0.0.1:61614' processes=31 threads=62, memory=123.56 GiB>\n",
      "\n",
      "Dask cluster ready for parallel processing!\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "from pathlib import Path\n",
    "# Configure Dask with MULTICORE processing for maximum speed\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.diagnostics import ProgressBar\n",
    "import multiprocessing\n",
    "\n",
    "# Get number of CPU cores\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Detected {n_cores} CPU cores\")\n",
    "\n",
    "# Create a local cluster with multiple workers (one per core)\n",
    "# Adjust n_workers and threads_per_worker based on your system\n",
    "cluster = LocalCluster(\n",
    "    n_workers=n_cores - 1,  # Leave 1 core free for system\n",
    "    threads_per_worker=2,    # 2 threads per worker\n",
    "    memory_limit='auto',     # Auto-detect memory per worker\n",
    "    processes=True,          # Use processes (not threads) for true parallelism\n",
    "    dashboard_address=':8787'  # Optional: view dashboard at localhost:8787\n",
    ")\n",
    "\n",
    "# Connect to the cluster\n",
    "client = Client(cluster)\n",
    "\n",
    "print(f\"Dask Client initialized with {n_cores - 1} workers\")\n",
    "print(f\"Dashboard available at: {client.dashboard_link}\")\n",
    "print(client)\n",
    "\n",
    "# Configure Dask settings for better performance\n",
    "dask.config.set({\n",
    "    'array.slicing.split_large_chunks': True,\n",
    "    'distributed.worker.memory.target': 0.7,\n",
    "    'distributed.worker.memory.spill': 0.8,\n",
    "    'distributed.worker.memory.pause': 0.9,\n",
    "    'distributed.scheduler.worker-saturation': 1.1,  # Allow slight oversubscription\n",
    "})\n",
    "\n",
    "print(\"\\nDask cluster ready for parallel processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17f60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FALSE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOURLY_DIR = Path(rf\"E:\\backup\\era5land_1970_2024_hourly\")      # directory with hourly files\n",
    "#MONTH_DIR = Path(rf\"E:\\backup\\trp_climate_model_data\\era5land_1970_2024_monthmean\")\n",
    "QUARTER_DIR = Path(rf\"E:\\backup\\trp_climate_model_data\\era5land_1970_2024_qtrmean\")\n",
    "#MONTH_DIR.mkdir(parents=True, exist_ok=True)    # output: quarterly means\n",
    "QUARTER_DIR.mkdir(parents=True, exist_ok=True)    # output: quarterly means\n",
    "\n",
    "# Configure the year range you want to process\n",
    "YEARS = range(1980, 1991)  # Process all years from 1980 to 2024\n",
    "\n",
    "# To test with a smaller range, use: YEARS = range(1980, 1981)\n",
    "QUARTERS = [\n",
    "    (\"01\", \"02\", \"03\"),  # Q1\n",
    "    (\"04\", \"05\", \"06\"),  # Q2\n",
    "    (\"07\", \"08\", \"09\"),  # Q3\n",
    "    (\"10\", \"11\", \"12\"),  # Q4\n",
    "]\n",
    "\n",
    "# Hourly filename pattern:\n",
    "# One file per month:    YYYY_MM.nc\n",
    "PATTERN_PER_MONTH = \"{y}_{m}.nc\"   # for one file per month\n",
    "#os.environ.setdefault(\"HDF5_USE_FILE_LOCKING\", \"FALSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqzxe12bodd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Check dataset structure to understand potential KeyError issues\n",
    "# FIXED: Handle all problematic variables including 'expver'\n",
    "\n",
    "# Open a sample file to inspect\n",
    "sample_file = 'E:\\\\backup\\\\download\\\\2000_01.nc'\n",
    "ds_inspect = xr.open_dataset(sample_file, engine='netcdf4')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDimensions: {dict(ds_inspect.dims)}\")\n",
    "print(f\"\\nCoordinates:\")\n",
    "for coord in ds_inspect.coords:\n",
    "    dtype = ds_inspect.coords[coord].dtype\n",
    "    shape = ds_inspect.coords[coord].shape\n",
    "    print(f\"  - {coord}: {dtype}, shape={shape}\")\n",
    "\n",
    "print(f\"\\nData Variables:\")\n",
    "for var in ds_inspect.data_vars:\n",
    "    dtype = ds_inspect[var].dtype\n",
    "    shape = ds_inspect[var].shape\n",
    "    print(f\"  - {var}: {dtype}, shape={shape}\")\n",
    "\n",
    "print(f\"\\nAttributes: {list(ds_inspect.attrs.keys())}\")\n",
    "\n",
    "# Check for problematic variables that can't be averaged\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING FOR PROBLEMATIC VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Drop scalar coordinates and object types before resampling\n",
    "vars_to_drop = []\n",
    "\n",
    "# Check all coordinates\n",
    "for coord in ds_inspect.coords:\n",
    "    coord_var = ds_inspect.coords[coord]\n",
    "    \n",
    "    # Drop if it's object type (like 'expver')\n",
    "    if coord_var.dtype == 'object' or coord_var.dtype.kind == 'O' or coord_var.dtype.kind == 'U':\n",
    "        vars_to_drop.append(coord)\n",
    "        print(f\"  Will drop coordinate: {coord} (object/string type, can't average)\")\n",
    "    # Drop if it's scalar (like 'number')\n",
    "    elif coord_var.ndim == 0:\n",
    "        vars_to_drop.append(coord)\n",
    "        print(f\"  Will drop coordinate: {coord} (scalar, can't resample)\")\n",
    "    # Drop if it doesn't have valid_time dimension (except lat/lon)\n",
    "    elif 'valid_time' not in coord_var.dims and coord not in ['latitude', 'longitude', 'valid_time']:\n",
    "        vars_to_drop.append(coord)\n",
    "        print(f\"  Will drop coordinate: {coord} (no time dimension)\")\n",
    "\n",
    "# Check data variable types\n",
    "for var in ds_inspect.data_vars:\n",
    "    if ds_inspect[var].dtype == 'object' or ds_inspect[var].dtype.kind == 'O' or ds_inspect[var].dtype.kind == 'U':\n",
    "        vars_to_drop.append(var)\n",
    "        print(f\"  Will drop variable: {var} (object type, can't average)\")\n",
    "\n",
    "if vars_to_drop:\n",
    "    print(f\"\\nDropping {len(vars_to_drop)} problematic variables: {vars_to_drop}\")\n",
    "    ds_clean = ds_inspect.drop_vars(vars_to_drop)\n",
    "else:\n",
    "    print(f\"\\nNo problematic variables found\")\n",
    "    ds_clean = ds_inspect\n",
    "\n",
    "# Check after resampling\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AFTER RESAMPLING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    monthly_inspect = ds_clean.resample(valid_time='M').mean()\n",
    "\n",
    "    print(f\"\\nDimensions: {dict(monthly_inspect.dims)}\")\n",
    "    print(f\"\\nCoordinates:\")\n",
    "    for coord in monthly_inspect.coords:\n",
    "        print(f\"  - {coord}: {monthly_inspect.coords[coord].dtype}\")\n",
    "\n",
    "    print(f\"\\nData Variables:\")\n",
    "    for var in monthly_inspect.data_vars:\n",
    "        print(f\"  - {var}: {monthly_inspect[var].dtype}\")\n",
    "    \n",
    "    print(\"\\n✓ Resampling successful!\")\n",
    "    \n",
    "    # Clean up\n",
    "    monthly_inspect.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ ERROR during resampling: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "ds_clean.close()\n",
    "ds_inspect.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adu26031o5p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hourly to quarterly processing...\n",
      "Input directory: E:\\backup\\era5land_1970_2024_hourly\n",
      "Output directory: E:\\backup\\trp_climate_model_data\\era5land_1970_2024_qtrmean\n",
      "Processing years: [2020, 2021, 2022, 2023, 2024]\n",
      "============================================================\n",
      "\n",
      "[exists] 2020_Q1_qmean.nc - skipping\n",
      "[exists] 2020_Q2_qmean.nc - skipping\n",
      "[exists] 2020_Q3_qmean.nc - skipping\n",
      "[exists] 2020_Q4_qmean.nc - skipping\n",
      "[exists] 2021_Q1_qmean.nc - skipping\n",
      "[exists] 2021_Q2_qmean.nc - skipping\n",
      "[exists] 2021_Q3_qmean.nc - skipping\n",
      "[exists] 2021_Q4_qmean.nc - skipping\n",
      "[exists] 2022_Q1_qmean.nc - skipping\n",
      "[exists] 2022_Q2_qmean.nc - skipping\n",
      "[exists] 2022_Q3_qmean.nc - skipping\n",
      "[exists] 2022_Q4_qmean.nc - skipping\n",
      "[processing] 2023 Q1 - combining 3 file(s)\n",
      "  Loaded: Frozen({'valid_time': 2160, 'latitude': 1801, 'longitude': 3600})\n",
      "  Dropping 2 problematic variable(s): ['number', 'expver']\n",
      "  Resampling to quarterly frequency...\n",
      "  Quarterly shape: Frozen({'valid_time': 1, 'latitude': 1801, 'longitude': 3600})\n",
      "  Computing in parallel...\n",
      "  Saving to disk...\n",
      "  ✓ Completed: 2023_Q1_qmean.nc (254.97s)\n",
      "\n",
      "[processing] 2023 Q2 - combining 3 file(s)\n",
      "  Loaded: Frozen({'valid_time': 2184, 'latitude': 1801, 'longitude': 3600})\n",
      "  Dropping 2 problematic variable(s): ['number', 'expver']\n",
      "  Resampling to quarterly frequency...\n",
      "  Quarterly shape: Frozen({'valid_time': 1, 'latitude': 1801, 'longitude': 3600})\n",
      "  Computing in parallel...\n",
      "  Saving to disk...\n",
      "  ✓ Completed: 2023_Q2_qmean.nc (256.59s)\n",
      "\n",
      "[exists] 2023_Q3_qmean.nc - skipping\n",
      "[exists] 2023_Q4_qmean.nc - skipping\n",
      "[exists] 2024_Q1_qmean.nc - skipping\n",
      "[exists] 2024_Q2_qmean.nc - skipping\n",
      "[exists] 2024_Q3_qmean.nc - skipping\n",
      "[processing] 2024 Q4 - combining 3 file(s)\n",
      "  Loaded: Frozen({'valid_time': 2208, 'latitude': 1801, 'longitude': 3600})\n",
      "  Dropping 2 problematic variable(s): ['number', 'expver']\n",
      "  Resampling to quarterly frequency...\n",
      "  Quarterly shape: Frozen({'valid_time': 1, 'latitude': 1801, 'longitude': 3600})\n",
      "  Computing in parallel...\n",
      "  Saving to disk...\n",
      "  ✓ Completed: 2024_Q4_qmean.nc (262.67s)\n",
      "\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE!\n",
      "============================================================\n",
      "Total time: 774.24 seconds (12.90 minutes)\n",
      "Processed: 3 quarters\n",
      "Skipped (existing): 0 quarters\n",
      "Errors: 0 quarters\n",
      "Average time per quarter: 258.08 seconds\n",
      "Output directory: E:\\backup\\trp_climate_model_data\\era5land_1970_2024_qtrmean\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE WORKFLOW: Process ALL YEARS and QUARTERS with multicore processing\n",
    "# FIXED: Handles ALL problematic variables including 'number' and 'expver'\n",
    "# FIXED: Compute data in memory before saving to avoid shape mismatch with resample()\n",
    "\n",
    "import time\n",
    "\n",
    "# --------------------------\n",
    "# PROCESS HOURLY → QUARTERLY\n",
    "# --------------------------\n",
    "print(\"Starting hourly to quarterly processing...\")\n",
    "print(f\"Input directory: {HOURLY_DIR}\")\n",
    "print(f\"Output directory: {QUARTER_DIR}\")\n",
    "print(f\"Processing years: {list(YEARS)}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "total_processed = 0\n",
    "total_skipped = 0\n",
    "total_errors = 0\n",
    "overall_start = time.time()\n",
    "\n",
    "for y in YEARS:\n",
    "    y = int(y)\n",
    "    for q_idx, (m1, m2, m3) in enumerate(QUARTERS, start=1):\n",
    "        try:\n",
    "            # Gather monthly hourly files for the quarter\n",
    "            files_to_process = []\n",
    "            for month in [m1, m2, m3]:\n",
    "                monthly_file = HOURLY_DIR / PATTERN_PER_MONTH.format(y=y, m=month)\n",
    "                if monthly_file.exists():\n",
    "                    files_to_process.append(str(monthly_file))\n",
    "                else:\n",
    "                    print(f\"  [warning] Missing: {monthly_file.name}\")\n",
    "\n",
    "            if not files_to_process:\n",
    "                print(f\"[skip] No hourly files for {y} Q{q_idx}\")\n",
    "                total_skipped += 1\n",
    "                continue\n",
    "\n",
    "            # Output file\n",
    "            q_out = QUARTER_DIR / f\"{y}_Q{q_idx}_qmean.nc\"\n",
    "\n",
    "            # If already exists, skip (comment out to reprocess)\n",
    "            if q_out.exists():\n",
    "                print(f\"[exists] {q_out.name} - skipping\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[processing] {y} Q{q_idx} - combining {len(files_to_process)} file(s)\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Open all files with parallel reading enabled\n",
    "            combined_ds = xr.open_mfdataset(\n",
    "                files_to_process,\n",
    "                engine='netcdf4',\n",
    "                chunks={'valid_time': 100, 'latitude': 600, 'longitude': 600},\n",
    "                parallel=True,\n",
    "                combine='by_coords',\n",
    "                coords='minimal',\n",
    "                compat='override'\n",
    "            )\n",
    "\n",
    "            print(f\"  Loaded: {combined_ds.dims}\")\n",
    "\n",
    "            # FIX: Drop ALL problematic variables before resampling\n",
    "            vars_to_drop = []\n",
    "            \n",
    "            # Check all coordinates for problematic types\n",
    "            for coord in combined_ds.coords:\n",
    "                coord_var = combined_ds.coords[coord]\n",
    "                \n",
    "                # Drop object/string types (like 'expver')\n",
    "                if coord_var.dtype == 'object' or coord_var.dtype.kind == 'O' or coord_var.dtype.kind == 'U':\n",
    "                    vars_to_drop.append(coord)\n",
    "                # Drop scalar coordinates (like 'number')\n",
    "                elif coord_var.ndim == 0:\n",
    "                    vars_to_drop.append(coord)\n",
    "                # Drop non-time-varying coordinates (except lat/lon)\n",
    "                elif 'valid_time' not in coord_var.dims and coord not in ['latitude', 'longitude', 'valid_time']:\n",
    "                    vars_to_drop.append(coord)\n",
    "            \n",
    "            # Drop object-type data variables\n",
    "            for var in combined_ds.data_vars:\n",
    "                if combined_ds[var].dtype == 'object' or combined_ds[var].dtype.kind == 'O' or combined_ds[var].dtype.kind == 'U':\n",
    "                    vars_to_drop.append(var)\n",
    "            \n",
    "            if vars_to_drop:\n",
    "                print(f\"  Dropping {len(vars_to_drop)} problematic variable(s): {vars_to_drop}\")\n",
    "                combined_ds = combined_ds.drop_vars(vars_to_drop)\n",
    "\n",
    "            # Resample to quarterly\n",
    "            print(f\"  Resampling to quarterly frequency...\")\n",
    "            quarterly_avg = combined_ds.resample(valid_time='Q').mean()\n",
    "            \n",
    "            # Add metadata\n",
    "            quarterly_avg.attrs['year'] = y\n",
    "            quarterly_avg.attrs['quarter'] = q_idx\n",
    "            quarterly_avg.attrs['description'] = f'Quarterly mean for {y} Q{q_idx}'\n",
    "            quarterly_avg.attrs['source'] = 'ERA5-Land hourly data'\n",
    "\n",
    "            print(f\"  Quarterly shape: {quarterly_avg.dims}\")\n",
    "            print(f\"  Computing in parallel...\")\n",
    "\n",
    "            # FIXED: Compute the data into memory BEFORE saving to avoid chunking/coordinate mismatch\n",
    "            quarterly_avg_computed = quarterly_avg.compute()\n",
    "\n",
    "            # Build encoding dict - ONLY for data variables, NOT coordinates\n",
    "            encoding = {}\n",
    "            for var in quarterly_avg_computed.data_vars:\n",
    "                encoding[var] = {\n",
    "                    'zlib': True, \n",
    "                    'complevel': 4, \n",
    "                    'dtype': 'float32',\n",
    "                    '_FillValue': -9999.0\n",
    "                }\n",
    "\n",
    "            # Save the computed data (no compute needed, data already in memory)\n",
    "            print(f\"  Saving to disk...\")\n",
    "            quarterly_avg_computed.to_netcdf(q_out, encoding=encoding)\n",
    "\n",
    "            # Cleanup\n",
    "            quarterly_avg_computed.close()\n",
    "            combined_ds.close()\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            total_processed += 1\n",
    "            \n",
    "            print(f\"  ✓ Completed: {q_out.name} ({elapsed:.2f}s)\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process {y} Q{q_idx}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            total_errors += 1\n",
    "            continue\n",
    "\n",
    "# Summary\n",
    "overall_elapsed = time.time() - overall_start\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PROCESSING COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total time: {overall_elapsed:.2f} seconds ({overall_elapsed/60:.2f} minutes)\")\n",
    "print(f\"Processed: {total_processed} quarters\")\n",
    "print(f\"Skipped (existing): {total_skipped} quarters\")\n",
    "print(f\"Errors: {total_errors} quarters\")\n",
    "if total_processed > 0:\n",
    "    print(f\"Average time per quarter: {overall_elapsed/total_processed:.2f} seconds\")\n",
    "print(f\"Output directory: {QUARTER_DIR}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe570f54",
   "metadata": {},
   "source": [
    "## Test File integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f761708b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File integrity checker functions loaded!\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# FILE INTEGRITY CHECKER\n",
    "# --------------------------\n",
    "\n",
    "def check_file_integrity(file_path, expected_vars=None, expected_dims=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Check the integrity of a NetCDF file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : Path or str\n",
    "        Path to the NetCDF file\n",
    "    expected_vars : list, optional\n",
    "        List of expected variable names\n",
    "    expected_dims : list, optional\n",
    "        List of expected dimension names\n",
    "    verbose : bool\n",
    "        Print detailed information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with integrity check results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'file': str(file_path),\n",
    "        'exists': False,\n",
    "        'readable': False,\n",
    "        'has_data': False,\n",
    "        'has_expected_vars': False,\n",
    "        'has_expected_dims': False,\n",
    "        'errors': [],\n",
    "        'warnings': [],\n",
    "        'info': {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check if file exists\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            results['errors'].append(\"File does not exist\")\n",
    "            return results\n",
    "        results['exists'] = True\n",
    "        \n",
    "        # Check file size\n",
    "        file_size = file_path.stat().st_size\n",
    "        results['info']['file_size_mb'] = round(file_size / (1024 * 1024), 2)\n",
    "        \n",
    "        if file_size == 0:\n",
    "            results['errors'].append(\"File is empty (0 bytes)\")\n",
    "            return results\n",
    "        \n",
    "        # Try to open the file\n",
    "        try:\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            results['readable'] = True\n",
    "        except Exception as e:\n",
    "            results['errors'].append(f\"Cannot open file: {str(e)}\")\n",
    "            return results\n",
    "        \n",
    "        # Check if dataset has data\n",
    "        if len(ds.data_vars) == 0:\n",
    "            results['errors'].append(\"No data variables found\")\n",
    "        else:\n",
    "            results['has_data'] = True\n",
    "            results['info']['num_vars'] = len(ds.data_vars)\n",
    "            results['info']['variables'] = list(ds.data_vars)\n",
    "        \n",
    "        # Check dimensions\n",
    "        results['info']['dimensions'] = dict(ds.dims)\n",
    "        \n",
    "        # Check for expected variables\n",
    "        if expected_vars:\n",
    "            missing_vars = set(expected_vars) - set(ds.data_vars)\n",
    "            if missing_vars:\n",
    "                results['warnings'].append(f\"Missing expected variables: {missing_vars}\")\n",
    "            else:\n",
    "                results['has_expected_vars'] = True\n",
    "        \n",
    "        # Check for expected dimensions\n",
    "        if expected_dims:\n",
    "            missing_dims = set(expected_dims) - set(ds.dims)\n",
    "            if missing_dims:\n",
    "                results['warnings'].append(f\"Missing expected dimensions: {missing_dims}\")\n",
    "            else:\n",
    "                results['has_expected_dims'] = True\n",
    "        \n",
    "        # Check for NaN or infinite values in each variable\n",
    "        for var in ds.data_vars:\n",
    "            try:\n",
    "                data = ds[var]\n",
    "                # Check dtype\n",
    "                if data.dtype == 'object':\n",
    "                    results['warnings'].append(f\"Variable '{var}' has object dtype (cannot be averaged)\")\n",
    "                    continue\n",
    "                \n",
    "                # For numeric data, check for issues\n",
    "                if data.dtype.kind in ['f', 'i', 'u']:  # float, int, unsigned int\n",
    "                    # Sample check (don't load entire array if it's huge)\n",
    "                    #if data.size > 1000000:  # If larger than 1M elements, sample\n",
    "                        #sample = data.isel({dim: slice(0, 100) for dim in data.dims})\n",
    "                    #else:\n",
    "                    sample = data\n",
    "                    \n",
    "                    # Load sample into memory\n",
    "                    sample_values = sample.values\n",
    "                    \n",
    "                    # Check for all NaN\n",
    "                    if np.all(np.isnan(sample_values)):\n",
    "                        results['warnings'].append(f\"Variable '{var}' appears to be all NaN\")\n",
    "                    \n",
    "                    # Check for any infinite values\n",
    "                    if np.any(np.isinf(sample_values)):\n",
    "                        results['warnings'].append(f\"Variable '{var}' contains infinite values\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                results['warnings'].append(f\"Could not check variable '{var}': {str(e)}\")\n",
    "        \n",
    "        # Check time dimension if present\n",
    "        if 'valid_time' in ds.dims:\n",
    "            results['info']['time_steps'] = ds.dims['valid_time']\n",
    "            try:\n",
    "                time_values = ds['valid_time'].values\n",
    "                results['info']['time_range'] = {\n",
    "                    'start': str(time_values[0]),\n",
    "                    'end': str(time_values[-1])\n",
    "                }\n",
    "            except:\n",
    "                results['warnings'].append(\"Could not read time values\")\n",
    "        \n",
    "        ds.close()\n",
    "        \n",
    "        # Overall status\n",
    "        if not results['errors']:\n",
    "            results['status'] = 'PASS' if not results['warnings'] else 'PASS_WITH_WARNINGS'\n",
    "        else:\n",
    "            results['status'] = 'FAIL'\n",
    "        \n",
    "    except Exception as e:\n",
    "        results['errors'].append(f\"Unexpected error: {str(e)}\")\n",
    "        results['status'] = 'FAIL'\n",
    "    \n",
    "    # Print results if verbose\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"File: {results['file']}\")\n",
    "        print(f\"Status: {results['status']}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        if results['info']:\n",
    "            print(\"\\nInfo:\")\n",
    "            for key, val in results['info'].items():\n",
    "                print(f\"  {key}: {val}\")\n",
    "        \n",
    "        if results['warnings']:\n",
    "            print(\"\\nWarnings:\")\n",
    "            for warn in results['warnings']:\n",
    "                print(f\"  ⚠ {warn}\")\n",
    "        \n",
    "        if results['errors']:\n",
    "            print(\"\\nErrors:\")\n",
    "            for err in results['errors']:\n",
    "                print(f\"  ✗ {err}\")\n",
    "        \n",
    "        if results['status'] == 'PASS':\n",
    "            print(\"\\n✓ File integrity check PASSED\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def check_multiple_files(file_pattern, expected_vars=None, expected_dims=None):\n",
    "    \"\"\"\n",
    "    Check integrity of multiple files matching a pattern.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_pattern : str\n",
    "        Glob pattern for files to check (e.g., \"data/*.nc\")\n",
    "    expected_vars : list, optional\n",
    "        List of expected variable names\n",
    "    expected_dims : list, optional\n",
    "        List of expected dimension names\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Summary of all file checks\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    \n",
    "    files = sorted(glob.glob(str(file_pattern)))\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found matching pattern: {file_pattern}\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"Checking {len(files)} file(s)...\")\n",
    "    \n",
    "    results = {}\n",
    "    summary = {\n",
    "        'total': len(files),\n",
    "        'passed': 0,\n",
    "        'passed_with_warnings': 0,\n",
    "        'failed': 0\n",
    "    }\n",
    "    \n",
    "    for file in files:\n",
    "        result = check_file_integrity(file, expected_vars, expected_dims, verbose=False)\n",
    "        results[file] = result\n",
    "        \n",
    "        if result['status'] == 'PASS':\n",
    "            summary['passed'] += 1\n",
    "        elif result['status'] == 'PASS_WITH_WARNINGS':\n",
    "            summary['passed_with_warnings'] += 1\n",
    "        else:\n",
    "            summary['failed'] += 1\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total files: {summary['total']}\")\n",
    "    print(f\"Passed: {summary['passed']}\")\n",
    "    print(f\"Passed with warnings: {summary['passed_with_warnings']}\")\n",
    "    print(f\"Failed: {summary['failed']}\")\n",
    "    \n",
    "    # Show failed files\n",
    "    if summary['failed'] > 0:\n",
    "        print(f\"\\nFailed files:\")\n",
    "        for file, result in results.items():\n",
    "            if result['status'] == 'FAIL':\n",
    "                print(f\"  ✗ {Path(file).name}\")\n",
    "                for err in result['errors']:\n",
    "                    print(f\"      - {err}\")\n",
    "    \n",
    "    # Show warnings\n",
    "    files_with_warnings = [f for f, r in results.items() if r['warnings']]\n",
    "    if files_with_warnings:\n",
    "        print(f\"\\nFiles with warnings: {len(files_with_warnings)}\")\n",
    "        for file in files_with_warnings[:5]:  # Show first 5\n",
    "            print(f\"  ⚠ {Path(file).name}\")\n",
    "            for warn in results[file]['warnings'][:2]:  # Show first 2 warnings\n",
    "                print(f\"      - {warn}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"File integrity checker functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a96856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 180 file(s)...\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Total files: 180\n",
      "Passed: 180\n",
      "Passed with warnings: 0\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# USAGE EXAMPLES FOR FILE INTEGRITY CHECKER\n",
    "# --------------------------\n",
    "\n",
    "#Example 1: Check a single file\n",
    "#result = check_file_integrity(HOURLY_DIR / \"1980_01.nc\")\n",
    "\n",
    "#Example 2: Check a single file with expected variables and dimensions\n",
    "# result = check_file_integrity(\n",
    "#     HOURLY_DIR / \"1980_01.nc\",\n",
    "#     expected_vars=['t2m', 'tp'],  # temperature and precipitation\n",
    "#     expected_dims=['time', 'latitude', 'longitude']\n",
    "# )\n",
    "\n",
    "#Example 3: Check all hourly files for a specific year\n",
    "#results = check_multiple_files(str(QUARTER_DIR / \"2004_*.nc\"))\n",
    "\n",
    "#Example 4: Check all quarterly output files\n",
    "results = check_multiple_files(str(QUARTER_DIR / \"*_qmean.nc\"))\n",
    "\n",
    "#Example 5: Check all hourly files in the directory\n",
    "#results = check_multiple_files(str(HOURLY_DIR / \"*.nc\"))\n",
    "\n",
    "#print(\"Uncomment the examples above to run integrity checks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e73e79",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9137f3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:     (valid_time: 1, latitude: 1801, longitude: 3600)\n",
       "Coordinates:\n",
       "  * latitude    (latitude) float64 90.0 89.9 89.8 89.7 ... -89.8 -89.9 -90.0\n",
       "  * longitude   (longitude) float64 0.0 0.1 0.2 0.3 ... 359.6 359.7 359.8 359.9\n",
       "  * valid_time  (valid_time) datetime64[ns] 2022-12-31\n",
       "Data variables:\n",
       "    tp          (valid_time, latitude, longitude) float32 ...\n",
       "    t2m         (valid_time, latitude, longitude) float32 ...\n",
       "    e           (valid_time, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    GRIB_centre:             ecmf\n",
       "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             European Centre for Medium-Range Weather Forecasts\n",
       "    history:                 2025-06-01T17:49 GRIB to CDM+CF via cfgrib-0.9.1...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-20a643c9-c81f-4e0c-b76a-a34518fc0f9d' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-20a643c9-c81f-4e0c-b76a-a34518fc0f9d' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>valid_time</span>: 1</li><li><span class='xr-has-index'>latitude</span>: 1801</li><li><span class='xr-has-index'>longitude</span>: 3600</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-00dacbb1-97ef-4a2a-a7a8-91f6daeb04a9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-00dacbb1-97ef-4a2a-a7a8-91f6daeb04a9' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>90.0 89.9 89.8 ... -89.9 -90.0</div><input id='attrs-50d107fc-1ec3-43d5-8523-bccdba800794' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-50d107fc-1ec3-43d5-8523-bccdba800794' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b9d4dab3-320d-4962-a933-7605131fe9ff' class='xr-var-data-in' type='checkbox'><label for='data-b9d4dab3-320d-4962-a933-7605131fe9ff' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>stored_direction :</span></dt><dd>decreasing</dd></dl></div><div class='xr-var-data'><pre>array([ 90. ,  89.9,  89.8, ..., -89.8, -89.9, -90. ])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 0.1 0.2 ... 359.7 359.8 359.9</div><input id='attrs-af16496c-18b6-41a2-b150-881955a3c717' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-af16496c-18b6-41a2-b150-881955a3c717' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4643098e-bb84-4895-a1f5-2a9e4e300b8d' class='xr-var-data-in' type='checkbox'><label for='data-4643098e-bb84-4895-a1f5-2a9e4e300b8d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd></dl></div><div class='xr-var-data'><pre>array([0.000e+00, 1.000e-01, 2.000e-01, ..., 3.597e+02, 3.598e+02, 3.599e+02])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>valid_time</span></div><div class='xr-var-dims'>(valid_time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2022-12-31</div><input id='attrs-6bd3535d-4cda-413e-bc4d-bfc4810c7ae2' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6bd3535d-4cda-413e-bc4d-bfc4810c7ae2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e374c448-419f-489b-b36c-bfb1ad726e1e' class='xr-var-data-in' type='checkbox'><label for='data-e374c448-419f-489b-b36c-bfb1ad726e1e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2022-12-31T00:00:00.000000000&#x27;], dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-cbb2d1c1-3d8b-46bf-9a65-0d05c8dce29c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-cbb2d1c1-3d8b-46bf-9a65-0d05c8dce29c' class='xr-section-summary' >Data variables: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>tp</span></div><div class='xr-var-dims'>(valid_time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-6e278c78-d4e1-4c6f-81df-809803b7d52a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6e278c78-d4e1-4c6f-81df-809803b7d52a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-822e80e3-a6bd-47bf-9b26-a9ad97bb8bf9' class='xr-var-data-in' type='checkbox'><label for='data-822e80e3-a6bd-47bf-9b26-a9ad97bb8bf9' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>GRIB_paramId :</span></dt><dd>228</dd><dt><span>GRIB_dataType :</span></dt><dd>fc</dd><dt><span>GRIB_numberOfPoints :</span></dt><dd>6483600</dd><dt><span>GRIB_typeOfLevel :</span></dt><dd>surface</dd><dt><span>GRIB_stepUnits :</span></dt><dd>1</dd><dt><span>GRIB_stepType :</span></dt><dd>accum</dd><dt><span>GRIB_gridType :</span></dt><dd>regular_ll</dd><dt><span>GRIB_uvRelativeToGrid :</span></dt><dd>0</dd><dt><span>GRIB_NV :</span></dt><dd>0</dd><dt><span>GRIB_Nx :</span></dt><dd>3600</dd><dt><span>GRIB_Ny :</span></dt><dd>1801</dd><dt><span>GRIB_cfName :</span></dt><dd>unknown</dd><dt><span>GRIB_cfVarName :</span></dt><dd>tp</dd><dt><span>GRIB_gridDefinitionDescription :</span></dt><dd>Latitude/Longitude Grid</dd><dt><span>GRIB_iDirectionIncrementInDegrees :</span></dt><dd>0.1</dd><dt><span>GRIB_iScansNegatively :</span></dt><dd>0</dd><dt><span>GRIB_jDirectionIncrementInDegrees :</span></dt><dd>0.1</dd><dt><span>GRIB_jPointsAreConsecutive :</span></dt><dd>0</dd><dt><span>GRIB_jScansPositively :</span></dt><dd>0</dd><dt><span>GRIB_latitudeOfFirstGridPointInDegrees :</span></dt><dd>90.0</dd><dt><span>GRIB_latitudeOfLastGridPointInDegrees :</span></dt><dd>-90.0</dd><dt><span>GRIB_longitudeOfFirstGridPointInDegrees :</span></dt><dd>0.0</dd><dt><span>GRIB_longitudeOfLastGridPointInDegrees :</span></dt><dd>359.9</dd><dt><span>GRIB_missingValue :</span></dt><dd>3.4028234663852886e+38</dd><dt><span>GRIB_name :</span></dt><dd>Total precipitation</dd><dt><span>GRIB_shortName :</span></dt><dd>tp</dd><dt><span>GRIB_totalNumber :</span></dt><dd>0</dd><dt><span>GRIB_units :</span></dt><dd>m</dd><dt><span>long_name :</span></dt><dd>Total precipitation</dd><dt><span>units :</span></dt><dd>m</dd><dt><span>standard_name :</span></dt><dd>unknown</dd><dt><span>GRIB_surface :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[6483600 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>t2m</span></div><div class='xr-var-dims'>(valid_time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-41b86237-371d-486b-9134-34cee57fc75a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-41b86237-371d-486b-9134-34cee57fc75a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9c418e2d-09b8-485b-abc6-4ac2715aeaf5' class='xr-var-data-in' type='checkbox'><label for='data-9c418e2d-09b8-485b-abc6-4ac2715aeaf5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>GRIB_paramId :</span></dt><dd>167</dd><dt><span>GRIB_dataType :</span></dt><dd>fc</dd><dt><span>GRIB_numberOfPoints :</span></dt><dd>6483600</dd><dt><span>GRIB_typeOfLevel :</span></dt><dd>surface</dd><dt><span>GRIB_stepUnits :</span></dt><dd>1</dd><dt><span>GRIB_stepType :</span></dt><dd>instant</dd><dt><span>GRIB_gridType :</span></dt><dd>regular_ll</dd><dt><span>GRIB_uvRelativeToGrid :</span></dt><dd>0</dd><dt><span>GRIB_NV :</span></dt><dd>0</dd><dt><span>GRIB_Nx :</span></dt><dd>3600</dd><dt><span>GRIB_Ny :</span></dt><dd>1801</dd><dt><span>GRIB_cfName :</span></dt><dd>unknown</dd><dt><span>GRIB_cfVarName :</span></dt><dd>t2m</dd><dt><span>GRIB_gridDefinitionDescription :</span></dt><dd>Latitude/Longitude Grid</dd><dt><span>GRIB_iDirectionIncrementInDegrees :</span></dt><dd>0.1</dd><dt><span>GRIB_iScansNegatively :</span></dt><dd>0</dd><dt><span>GRIB_jDirectionIncrementInDegrees :</span></dt><dd>0.1</dd><dt><span>GRIB_jPointsAreConsecutive :</span></dt><dd>0</dd><dt><span>GRIB_jScansPositively :</span></dt><dd>0</dd><dt><span>GRIB_latitudeOfFirstGridPointInDegrees :</span></dt><dd>90.0</dd><dt><span>GRIB_latitudeOfLastGridPointInDegrees :</span></dt><dd>-90.0</dd><dt><span>GRIB_longitudeOfFirstGridPointInDegrees :</span></dt><dd>0.0</dd><dt><span>GRIB_longitudeOfLastGridPointInDegrees :</span></dt><dd>359.9</dd><dt><span>GRIB_missingValue :</span></dt><dd>3.4028234663852886e+38</dd><dt><span>GRIB_name :</span></dt><dd>2 metre temperature</dd><dt><span>GRIB_shortName :</span></dt><dd>2t</dd><dt><span>GRIB_totalNumber :</span></dt><dd>0</dd><dt><span>GRIB_units :</span></dt><dd>K</dd><dt><span>long_name :</span></dt><dd>2 metre temperature</dd><dt><span>units :</span></dt><dd>K</dd><dt><span>standard_name :</span></dt><dd>unknown</dd><dt><span>GRIB_surface :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[6483600 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>e</span></div><div class='xr-var-dims'>(valid_time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-07ad41f6-6a4b-4672-a4ac-45240e9f215f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-07ad41f6-6a4b-4672-a4ac-45240e9f215f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4bf40113-3044-40d1-910c-6e0885323c33' class='xr-var-data-in' type='checkbox'><label for='data-4bf40113-3044-40d1-910c-6e0885323c33' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>GRIB_paramId :</span></dt><dd>182</dd><dt><span>GRIB_dataType :</span></dt><dd>fc</dd><dt><span>GRIB_numberOfPoints :</span></dt><dd>6483600</dd><dt><span>GRIB_typeOfLevel :</span></dt><dd>surface</dd><dt><span>GRIB_stepUnits :</span></dt><dd>1</dd><dt><span>GRIB_stepType :</span></dt><dd>accum</dd><dt><span>GRIB_gridType :</span></dt><dd>regular_ll</dd><dt><span>GRIB_uvRelativeToGrid :</span></dt><dd>0</dd><dt><span>GRIB_NV :</span></dt><dd>0</dd><dt><span>GRIB_Nx :</span></dt><dd>3600</dd><dt><span>GRIB_Ny :</span></dt><dd>1801</dd><dt><span>GRIB_cfName :</span></dt><dd>lwe_thickness_of_water_evaporation_amount</dd><dt><span>GRIB_cfVarName :</span></dt><dd>e</dd><dt><span>GRIB_gridDefinitionDescription :</span></dt><dd>Latitude/Longitude Grid</dd><dt><span>GRIB_iDirectionIncrementInDegrees :</span></dt><dd>0.1</dd><dt><span>GRIB_iScansNegatively :</span></dt><dd>0</dd><dt><span>GRIB_jDirectionIncrementInDegrees :</span></dt><dd>0.1</dd><dt><span>GRIB_jPointsAreConsecutive :</span></dt><dd>0</dd><dt><span>GRIB_jScansPositively :</span></dt><dd>0</dd><dt><span>GRIB_latitudeOfFirstGridPointInDegrees :</span></dt><dd>90.0</dd><dt><span>GRIB_latitudeOfLastGridPointInDegrees :</span></dt><dd>-90.0</dd><dt><span>GRIB_longitudeOfFirstGridPointInDegrees :</span></dt><dd>0.0</dd><dt><span>GRIB_longitudeOfLastGridPointInDegrees :</span></dt><dd>359.9</dd><dt><span>GRIB_missingValue :</span></dt><dd>3.4028234663852886e+38</dd><dt><span>GRIB_name :</span></dt><dd>Evaporation</dd><dt><span>GRIB_shortName :</span></dt><dd>e</dd><dt><span>GRIB_totalNumber :</span></dt><dd>0</dd><dt><span>GRIB_units :</span></dt><dd>m of water equivalent</dd><dt><span>long_name :</span></dt><dd>Evaporation</dd><dt><span>units :</span></dt><dd>m of water equivalent</dd><dt><span>standard_name :</span></dt><dd>lwe_thickness_of_water_evaporation_amount</dd><dt><span>GRIB_surface :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[6483600 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-e29fec83-73aa-443e-ac50-f9c90cb988c5' class='xr-section-summary-in' type='checkbox'  ><label for='section-e29fec83-73aa-443e-ac50-f9c90cb988c5' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-28fc3d34-c3ff-48df-8618-16a86e7d11ad' class='xr-index-data-in' type='checkbox'/><label for='index-28fc3d34-c3ff-48df-8618-16a86e7d11ad' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([              90.0,               89.9,  89.80000000000001,\n",
       "        89.70000000000002,  89.60000000000002,  89.50000000000003,\n",
       "        89.40000000000003,  89.30000000000004,  89.20000000000005,\n",
       "        89.10000000000005,\n",
       "       ...\n",
       "       -89.09999999999837, -89.19999999999837, -89.29999999999836,\n",
       "       -89.39999999999836, -89.49999999999835, -89.59999999999835,\n",
       "       -89.69999999999834, -89.79999999999833, -89.89999999999833,\n",
       "                    -90.0],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;latitude&#x27;, length=1801))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b0499d56-f6cb-4e3b-a97c-a364b9fb5d71' class='xr-index-data-in' type='checkbox'/><label for='index-b0499d56-f6cb-4e3b-a97c-a364b9fb5d71' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([                0.0, 0.09999999999999999, 0.19999999999999998,\n",
       "                       0.3, 0.39999999999999997, 0.49999999999999994,\n",
       "                       0.6,                 0.7,  0.7999999999999999,\n",
       "        0.8999999999999999,\n",
       "       ...\n",
       "        359.00000000001313,  359.10000000001315,   359.2000000000132,\n",
       "         359.3000000000132,   359.4000000000132,  359.50000000001324,\n",
       "        359.60000000001327,   359.7000000000133,   359.8000000000133,\n",
       "                     359.9],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;longitude&#x27;, length=3600))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>valid_time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-68753741-7f7f-4f71-baea-09afd53b386c' class='xr-index-data-in' type='checkbox'/><label for='index-68753741-7f7f-4f71-baea-09afd53b386c' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2022-12-31&#x27;], dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;valid_time&#x27;, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-2decdcfc-e2d0-4a08-b9d9-9f7bd1b9d4c6' class='xr-section-summary-in' type='checkbox'  checked><label for='section-2decdcfc-e2d0-4a08-b9d9-9f7bd1b9d4c6' class='xr-section-summary' >Attributes: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>GRIB_centre :</span></dt><dd>ecmf</dd><dt><span>GRIB_centreDescription :</span></dt><dd>European Centre for Medium-Range Weather Forecasts</dd><dt><span>GRIB_subCentre :</span></dt><dd>0</dd><dt><span>Conventions :</span></dt><dd>CF-1.7</dd><dt><span>institution :</span></dt><dd>European Centre for Medium-Range Weather Forecasts</dd><dt><span>history :</span></dt><dd>2025-06-01T17:49 GRIB to CDM+CF via cfgrib-0.9.15.0/ecCodes-2.41.0 with {&quot;source&quot;: &quot;data.grib&quot;, &quot;filter_by_keys&quot;: {}, &quot;encode_cf&quot;: [&quot;parameter&quot;, &quot;time&quot;, &quot;geography&quot;, &quot;vertical&quot;]}</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:     (valid_time: 1, latitude: 1801, longitude: 3600)\n",
       "Coordinates:\n",
       "  * latitude    (latitude) float64 90.0 89.9 89.8 89.7 ... -89.8 -89.9 -90.0\n",
       "  * longitude   (longitude) float64 0.0 0.1 0.2 0.3 ... 359.6 359.7 359.8 359.9\n",
       "  * valid_time  (valid_time) datetime64[ns] 2022-12-31\n",
       "Data variables:\n",
       "    tp          (valid_time, latitude, longitude) float32 ...\n",
       "    t2m         (valid_time, latitude, longitude) float32 ...\n",
       "    e           (valid_time, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    GRIB_centre:             ecmf\n",
       "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             European Centre for Medium-Range Weather Forecasts\n",
       "    history:                 2025-06-01T17:49 GRIB to CDM+CF via cfgrib-0.9.1..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = xr.open_dataset(rf'E:\\backup\\trp_climate_model_data\\era5land_1970_2024_qtrmean\\2022_Q4_qmean.nc', engine='netcdf4')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19f27a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4 = [rf'E:/backup/download/2004_10.nc',\n",
    " rf'E:/backup/download/2004_11.nc',\n",
    " rf'E:/backup/download/2004_12.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9593edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(rf'E:/backup/download/2004_12.nc', engine='netcdf4')\n",
    "ds['e'].values\n",
    "ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
